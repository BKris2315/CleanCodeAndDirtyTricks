{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CleanCodeAndDirtyTricks üöÄ\n",
    "## Session 02: Optimize that snake! üêç\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 15%;\">\n",
    "<img src=\"imgs/logo_rot.png\" alt=\"Drawing\" style=\"width: 50px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 80%;\">\n",
    "<img src=\"imgs/speed_up.png\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "@#DKOP#TTK#WJSZ#PHYSICS#ComputerScience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üßµ Topics We'll Cover\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### üöÄ Just-In-Time (JIT) Compiling\n",
    "\n",
    "- **Numba** ‚Äì Accelerate loops and math-heavy code\n",
    "- **JAX** ‚Äì Auto-differentiation + JIT + GPU/TPU-ready\n",
    "- **PyPy** ‚Äì Drop-in faster Python interpreter\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Parallelism & Concurrency\n",
    "\n",
    "- **Multiprocessing** ‚Äì True parallelism using processes\n",
    "- **Multithreading** ‚Äì Limited by GIL, but useful for I/O\n",
    "- **GIL (Global Interpreter Lock)** ‚Äì What it is and why it matters\n",
    "- **CuPy and PyTorch** \n",
    "</div>\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "\n",
    "### üß™ Other Performance Boosters\n",
    "\n",
    "- **Choosing the Right Interpreter**  \n",
    "  - CPython, PyPy, and beyond\n",
    "- **Benchmarking & Profiling**  \n",
    "  - `cProfile`, `line_profiler`, `memory_profiler`\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Goal of This Session\n",
    "\n",
    "- Learn **how Python works under the hood**\n",
    "- Discover **what tools to use when**\n",
    "- Write code that‚Äôs not just clean ‚Äî but **fast and scalable**\n",
    "\n",
    "</div>\n",
    "</div>\n",
    "> _‚ÄúPython isn‚Äôt slow ‚Äî your loops are.‚Äù_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disclaimer\n",
    "\n",
    "Almost every figure is borrowed from the articles listed among the **References**, or from Google. I do not claim authorship for any of those, they are used solely for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Why is Python Slow? - üîê Understanding the GIL  \n",
    "_The Global Interpreter Lock in Python_\n",
    "\n",
    "<img src=\"imgs/What-is-the-Python-Global-Interpreter-Lock-GIL_Watermarked.0695d8c16efe.avif\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üß† What Is the GIL?\n",
    "\n",
    "- The GIL is a **mutex (lock)** that ensures **only one thread executes Python bytecode at a time**, even on multi-core systems.\n",
    "- Originally introduced in **CPython** to protect memory during **reference counting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üîç Why Does It Exist?\n",
    "\n",
    "- Prevents **race conditions** during memory management (ref counting).\n",
    "- Avoids **deadlocks** by locking the entire interpreter instead of individual objects.\n",
    "- Simplifies integration with **C extensions**, many of which are not thread-safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Exmaple reference counting in Python:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "a = []\n",
    "b = a\n",
    "sys.getrefcount(a)\n",
    ">> 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üß® The Drawback\n",
    "\n",
    "- In **CPU-bound programs**, multithreading is ineffective:\n",
    "  - Threads fight for the GIL ‚Äî one runs, others wait.\n",
    "  - Only one CPU core is used effectively.\n",
    "\n",
    "### Not ideal for:\n",
    "- Heavy numerical computations\n",
    "- Data processing with many threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## ‚úÖ When It's Okay\n",
    "\n",
    "- **I/O-bound programs** (file, network, DB wait time):\n",
    "  - Threads can release the GIL while waiting\n",
    "  - Useful for concurrent I/O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üõ† How to Work Around It\n",
    "\n",
    "- Use **multiprocessing**: Each process has its own Python interpreter & GIL\n",
    "- Use **JIT compilers** (like **Numba**, **PyPy**) that reduce Python's need for the GIL\n",
    "- Offload to **GPU** (e.g., with **JAX**, **CuPy**) or C libraries\n",
    "\n",
    "---\n",
    "\n",
    "> _‚ÄúThe GIL makes Python simple and fast for single-threaded tasks ‚Äî but a bottleneck for CPU-bound parallelism.‚Äù_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other notable mentions\n",
    "\n",
    "- **Garbage collecting:** Garbage collection is a form of automatic memory management that a programming language runtime system uses to reclaim memory that is no longer in use by the program.\n",
    "- **Dynamic typing:** In addition, Python is dynamically typed, which means that you don¬¥t have to declare the type of a variable when you initialize it. Hence, in Python types are determined by the runtime, i.e. **the interpreter needs to do type-checking every time it executes a piece of code**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. ‚ö° Speeding Up Python with Numba\n",
    "<img src=\"imgs/python_fast.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üöÄ What is Numba?\n",
    "\n",
    "- **Numba** is a **Just-In-Time (JIT) compiler** for numerical Python.\n",
    "- Translates a subset of Python + NumPy into **fast machine code** using LLVM.\n",
    "- No need to rewrite your code in C or C++!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## üß™ How to Use It\n",
    "\n",
    "### Simple Example:\n",
    "```python\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def sum_numbers(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "```\n",
    "\n",
    "- First run compiles it ‚Äî next runs are üî• fast!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚úÖ Key Features\n",
    "\n",
    "- **@jit** ‚Äî main decorator for JIT compiling\n",
    "- **nopython mode** ‚Äî best performance (no Python objects allowed)\n",
    "- **parallel=True** ‚Äî multi-core execution\n",
    "- **@vectorize** and **@guvectorize** ‚Äî write your own fast NumPy ufuncs\n",
    "- **@jitclass** ‚Äî compile custom classes\n",
    "- Works with **NumPy**, supports **CUDA for GPUs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ö†Ô∏è When to Use Numba\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### Ideal for:\n",
    "- Loops, number-crunching, array processing\n",
    "- Tight, performance-critical functions\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### Avoid for:\n",
    "- Code with lots of objects or dynamic typing\n",
    "- Heavy use of Python standard library\n",
    "- I/O-bound code or logic-heavy app code\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üîß Numba: njit = Fastest Mode\n",
    "## üß† What‚Äôs `@njit`?\n",
    "\n",
    "- Short for **no-Python JIT** ‚Äî alias for `@jit(nopython=True)`\n",
    "- Forces Numba to compile in the fastest mode:\n",
    "  - No use of Python objects\n",
    "  - Fully converted to machine code\n",
    "- Errors if it can‚Äôt compile without Python runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### ‚úÖ Use This Instead of:\n",
    "```python\n",
    "@jit(nopython=True)\n",
    "def fast_func(x): ...\n",
    "```\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### ‚úÖ Cleaner:\n",
    "```python\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def fast_func(x): ...\n",
    "```\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "> üí° Best performance comes from sticking to NumPy arrays and numerical types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# üßµ Numba: Parallel Execution with `parallel=True`\n",
    "## üöÄ What It Does\n",
    "\n",
    "- Tells Numba to **auto-parallelize** your code across CPU cores\n",
    "- Use in `@jit` or `@njit`:\n",
    "\n",
    "```python\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def sum_parallel(arr):\n",
    "    total = 0.0\n",
    "    for i in prange(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "```\n",
    "\n",
    "- `prange` = parallel version of `range`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ö†Ô∏è Notes\n",
    "\n",
    "- Only works in **nopython mode**\n",
    "- Performance gains depend on problem size and CPU cores\n",
    "- Can be combined with vectorized operations too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üîç Check if Parallel Worked\n",
    "\n",
    "Run with:\n",
    "```bash\n",
    "NUMBA_DEBUG_ARRAY_OPT_STATS=1 python myscript.py\n",
    "```\n",
    "\n",
    "> _‚ÄúParallel=True is like turbo mode ‚Äî but use it only when you have real work to spread.‚Äù_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üìè Performance Tip\n",
    "\n",
    "- Always test with `nopython=True` and `parallel=True`\n",
    "- Profile with `%timeit`, `cProfile`, or `line_profiler`\n",
    "- Use Numba's built-in diagnostics (`numba --annotate-html`)\n",
    "\n",
    "> _‚ÄúWith one decorator, you can get C-like speed in Python.‚Äù_  \n",
    "‚Äî [Numba Docs](https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. ‚öôÔ∏è JAX: High-Performance Numerical Computing for Python\n",
    "<img src=\"imgs/jax_logo.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üöÄ What Is JAX?\n",
    "\n",
    "- A **NumPy-compatible** library with superpowers:\n",
    "  - Automatic **differentiation** (like TensorFlow or PyTorch)\n",
    "  - Fast execution via **XLA (Accelerated Linear Algebra)**\n",
    "  - Seamless support for **GPU and TPU** execution\n",
    "- Developed by Google; ideal for ML, simulations, scientific computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üîç Why JAX > NumPy?\n",
    "\n",
    "| Feature             | NumPy       | JAX                      |\n",
    "|---------------------|-------------|--------------------------|\n",
    "| GPU/TPU Support     | ‚ùå No        | ‚úÖ Built-in              |\n",
    "| Auto-Differentiation| ‚ùå No        | ‚úÖ With `grad()`         |\n",
    "| JIT Compilation     | ‚ùå No        | ‚úÖ With `@jit`           |\n",
    "| Parallelism         | Limited     | ‚úÖ With `pmap`, `vmap`   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß† Core Features\n",
    "\n",
    "- `jit(f)` ‚Üí Just-in-time compile any function  \n",
    "- `grad(f)` ‚Üí Auto compute gradients  \n",
    "- `vmap(f)` ‚Üí Vectorize functions easily  \n",
    "- `pmap(f)` ‚Üí Parallelize across multiple devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ú® Example\n",
    "\n",
    "```python\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "fast_square = jit(square)\n",
    "deriv = grad(square)\n",
    "\n",
    "print(fast_square(3.0))  # 9.0\n",
    "print(deriv(3.0))        # 6.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ö†Ô∏è Notes\n",
    "\n",
    "- Arrays are immutable\n",
    "- Debugging can be tricky (compiled under the hood)\n",
    "- Still maturing, especially for general-purpose computing\n",
    "\n",
    "\n",
    "> _‚ÄúJAX is NumPy on steroids, built for modern ML and hardware acceleration.‚Äù_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. ‚ö° CuPy: GPU-Accelerated NumPy\n",
    "<img src=\"imgs/cupy.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üöÄ What is CuPy?\n",
    "\n",
    "- A **NumPy-compatible** array library that runs on **GPU**\n",
    "- Built with CUDA ‚Äî designed for high-performance numerical computing\n",
    "- Drop-in replacement: just `import cupy as cp` instead of `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß† Key Features\n",
    "\n",
    "- Uses NVIDIA CUDA libraries under the hood (cuBLAS, cuDNN, cuFFT, etc.)\n",
    "- Supports broadcasting, indexing, ufuncs, slicing ‚Äî just like NumPy\n",
    "- 100x speed-up possible on some operations\n",
    "- Custom CUDA kernels via `ElementwiseKernel` or `RawKernel`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß™ Example Usage\n",
    "\n",
    "```python\n",
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2, 3).astype('f')\n",
    "print(x.sum(axis=1))  # Fast and GPU-accelerated\n",
    "```\n",
    "\n",
    "> Works just like NumPy, but much faster on large data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚öôÔ∏è Installation (pick your CUDA version)\n",
    "\n",
    "```bash\n",
    "pip install cupy-cuda11x  # For CUDA 11.x\n",
    "pip install cupy-cuda12x  # For CUDA 12.x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ö†Ô∏è Considerations\n",
    "\n",
    "- Requires **NVIDIA GPU** with CUDA support\n",
    "- Does not support every SciPy function (yet)\n",
    "- Performance gain only on **large arrays** and **numeric operations**\n",
    "\n",
    "\n",
    "> _‚ÄúIf you know NumPy, you already know CuPy ‚Äî just faster, on GPU.‚Äù_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. üî• PyTorch: Flexible Deep Learning Framework\n",
    "<img src=\"imgs/misc-pytorch-course-launch-cover-white-text-black-background.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß† What Is PyTorch?\n",
    "\n",
    "- An open-source deep learning library developed by Meta AI.\n",
    "- Combines a Pythonic interface with efficient GPU acceleration.\n",
    "- Widely adopted in both research and industry for its flexibility and ease of use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚öôÔ∏è Key Features\n",
    "\n",
    "- **Dynamic Computational Graphs**: Build and modify models on-the-fly, facilitating intuitive debugging and model customization.\n",
    "- **GPU Acceleration**: Seamless integration with CUDA for high-performance computations.\n",
    "- **Autograd Module**: Automatic differentiation for efficient gradient computation.\n",
    "- **TorchScript**: Convert models into a form that can be run independently from Python, enabling deployment in production environments.\n",
    "- **TorchServe**: A tool for serving PyTorch models at scale, supporting features like multi-model serving and RESTful endpoints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß™ Example: Simple Neural Network\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üì¶ Installation\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "```\n",
    "\n",
    "\n",
    "> _‚ÄúPyTorch offers a seamless path from research prototyping to production deployment.‚Äù_\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. ü§π Multithreading vs Multiprocessing in Python\n",
    "<img src=\"imgs/python_pool.webp\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ü§î Common Misconceptions\n",
    "\n",
    "> ‚õîÔ∏è **\"They're basically the same thing\"**\n",
    "\n",
    "- **Multithreading** uses threads (within the same process).\n",
    "- **Multiprocessing** uses separate processes (each with its own Python interpreter).\n",
    "- In Python, threads do not run *in true parallel* due to the GIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß™ Experiment #1: CPU-Heavy Tasks\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "def cpu_heavy(x):\n",
    "    for i in range(10**8):\n",
    "        pass\n",
    "```\n",
    "\n",
    "- `multithreading(cpu_heavy, range(4), 4)` ‚Üí ~20 sec  \n",
    "- `multiprocessing(cpu_heavy, range(4), 4)` ‚Üí ~5 sec  \n",
    "\n",
    "‚úÖ Multiprocessing is **much faster** for CPU-heavy tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ùó Why Threads Are Slower on CPU Tasks\n",
    "\n",
    "> **\"Threads run in parallel\"**\n",
    "\n",
    "- Actually, threads **share the same core** ‚Äî they take turns (concurrent, not parallel).\n",
    "- Only one thread runs at a time due to the **Global Interpreter Lock (GIL)**.\n",
    "- Switching threads adds **context-switch overhead**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"imgs/thread_proc_runtime.webp\" alt=\"Drawing\" style=\"width: 750px;\"/>\n",
    "\n",
    "Actually threads neither run in parallel nor in sequence. They run concurrently! Each time one job will be executed a little and then the other takes on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Experiment #2: Serial vs Threads\n",
    "\n",
    "- 4 CPU-bound jobs on 4 threads:\n",
    "```python\n",
    "for i in range(4): cpu_heavy(i)  # serial\n",
    "multithreading(cpu_heavy, range(4), 4)\n",
    "```\n",
    "\n",
    "Results:\n",
    "- **Serial:** ~1659 sec  \n",
    "- **Multithreading:** ~1669 sec  \n",
    "üõë Threads were slightly **slower** due to thread-switching overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ When Is Multithreading Actually Useful?\n",
    "\n",
    "> **\"Multithreading is useless\"**\n",
    "\n",
    "üîÅ **False** ‚Äî it's just not for CPU-bound tasks.\n",
    "\n",
    "üßµ **Multithreading shines with I/O-bound operations** like:\n",
    "- Downloading files\n",
    "- Reading from disk\n",
    "- Waiting on web responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "```python\n",
    "with urllib.request.urlopen(url) as conn:\n",
    "    data = conn.read()\n",
    "```\n",
    "\n",
    "- Serial I/O: ~7.8 sec  \n",
    "- Threads (4): ~2.6 sec  \n",
    "- Threads (8): ~1.5 sec  \n",
    "\n",
    "‚úÖ Threads help hide I/O **latency** by switching tasks while waiting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Packages for Multiprocessing/Multithreading\n",
    "\n",
    "- `concurrent.futures`\n",
    "- `multiprocessing`\n",
    "- `threading`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üìö Summary\n",
    "\n",
    "| Task Type       | Use                        |\n",
    "|------------------|-----------------------------|\n",
    "| CPU-heavy        | ‚úÖ Multiprocessing          |\n",
    "| I/O-bound        | ‚úÖ Multithreading           |\n",
    "| Mixed/General    | Depends ‚Äî profile it!       |\n",
    "\n",
    "---\n",
    "\n",
    "> _‚ÄúConcurrency ‚â† Parallelism ‚Äî understand the difference, and pick the right tool.‚Äù_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. üß© Beyond CPython: Other Python Interpreters\n",
    "<img src=\"imgs/interpreter.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üêç What Is CPython?\n",
    "\n",
    "- The **default** Python interpreter\n",
    "- Written in C ‚Äî what you run when you type `python`\n",
    "- Prioritizes **compatibility and stability**\n",
    "- BUT... has limitations like the **GIL** and **slower performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üöÄ Why Consider Other Interpreters?\n",
    "\n",
    "- üî• **Speed**: JIT compilers (PyPy) make some Python code much faster\n",
    "- üßµ **Concurrency**: Some interpreters don‚Äôt have a GIL (e.g. Jython, IronPython)\n",
    "- ü§ù **Interoperability**: Want to use Java or .NET libraries? Use Jython/IronPython.\n",
    "- üß™ **Experimentation**: For exploring new platforms or specialized environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## üß† Popular Alternatives\n",
    "\n",
    "| Interpreter     | Highlights                           |\n",
    "|----------------|--------------------------------------|\n",
    "| **PyPy**        | JIT compiled, much faster for many tasks |\n",
    "| **Jython**      | Python on the Java Virtual Machine   |\n",
    "| **IronPython**  | Python for .NET/Mono environments    |\n",
    "| **GraalPython** | Python via GraalVM, polyglot ready   |\n",
    "| **MicroPython** | Python for microcontrollers          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ‚ö†Ô∏è Keep in Mind\n",
    "\n",
    "- Not all packages work on all interpreters (e.g., C extensions on PyPy or Jython)\n",
    "- Trade-offs: speed vs ecosystem vs compatibility\n",
    "- Great for specific use cases ‚Äî not always a full replacement\n",
    "\n",
    "> _‚ÄúDifferent interpreters unlock different powers ‚Äî choose based on your problem, not just habit.‚Äù_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### ‚öôÔ∏è Python Performance & Optimization\n",
    "- [Why Python is slower than C](https://medium.com/thedeephub/but-why-python-is-so-slow-da1a4fb9be92)\n",
    "- [Numba from Scratch](https://pythonspeed.com/articles/numba-faster-python/)\n",
    "- [PyPy 101 ‚Äì Real Python](https://realpython.com/pypy-faster-python/)\n",
    "- [JIT Compilation (Numba Tutorial)](https://medium.com/data-science/make-python-run-as-fast-as-c-9fdccdb501d4)\n",
    "- [Speed Up with Numba ‚Äì Kaggle](https://www.kaggle.com/code/rudrasing/speed-up-python-code-up-to-100x-using-numba)\n",
    "- [Make python fast with numba](https://thedatafrog.com/en/articles/make-python-fast-numba/)\n",
    "- [PyPy Documentation](https://doc.pypy.org/en/latest/)\n",
    "- [JAX vs NumPy](https://medium.com/@harshavardhangv/jax-vs-numpy-key-differences-and-benefits-72e442bbf67f)\n",
    "- [Introduction to Jax](https://www.kaggle.com/code/goktugguvercin/introduction-to-jax)\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "### üßµ Multiprocessing & Parallelism\n",
    "\n",
    "- [Intro to Multiprocessing ‚Äì Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/04/a-beginners-guide-to-multi-processing-in-python/)\n",
    "- [Optimal Multiprocessing ‚Äì Medium](https://medium.com/@sampsa.riikonen/doing-python-multiprocessing-the-right-way-a54c1880e300)\n",
    "- [Threads vs Processes ‚Äì DataCamp](https://www.datacamp.com/tutorial/python-multiprocessing-tutorial)\n",
    "- [Threads vs Processes ‚Äì Contentsquare](https://engineering.contentsquare.com/2018/multithreading-vs-multiprocessing-in-python/)\n",
    "- [ProcessPoolExecutor Guide ‚Äì Medium](https://medium.com/@superfastpython/python-processpoolexecutor-7-day-crash-course-71cf062409d2)\n",
    "- [SuperfastPython ‚Äì ProcessPoolExecutor](https://superfastpython.com/processpoolexecutor-in-python/)\n",
    "- [RealPython on the GIL](https://realpython.com/python-gil/)\n",
    "- [High-Speed Execution Tips ‚Äì Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/01/optimize-python-code-for-high-speed-execution/)\n",
    "- [PyTorch mastery course](https://github.com/mrdbourke/pytorch-deep-learning?tab=readme-ov-file)\n",
    "- [multithreading-vs-multiprocessing](https://github.com/baatout/multithreading-vs-multiprocessing/tree/master)\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 48%;\">\n",
    "\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
